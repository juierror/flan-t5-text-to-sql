{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e97815e-9ab4-4d96-873d-4638bc3577c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Any, List\n",
    "from datasets import load_dataset, concatenate_datasets\n",
    "import evaluate\n",
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSeq2SeqLM\n",
    "from transformers import DataCollatorForSeq2Seq\n",
    "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af6e81d-f0cd-4cdf-98fa-c8b827382277",
   "metadata": {},
   "source": [
    "# Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76dc86ff-cb06-4c4d-bc53-30776c4444fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-base\")\n",
    "tokenizer.add_tokens([\"<\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c63d55e-5274-481b-908c-1d47409899d9",
   "metadata": {},
   "source": [
    "## Spider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e835d2aa-6a52-4f9a-ba79-96524471f6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare table for cosql and sparc\n",
    "with open(\"cosql_dataset/tables.json\") as json_file:\n",
    "    json_data = json.load(json_file)\n",
    "    \n",
    "database = dict()\n",
    "\n",
    "for db in json_data:\n",
    "    database[db[\"db_id\"]] = dict()\n",
    "    for table in db[\"table_names_original\"]:\n",
    "        database[db[\"db_id\"]][table] = []\n",
    "    for column in db[\"column_names_original\"]:\n",
    "        table_id = column[0]\n",
    "        col_name = column[1]\n",
    "        if table_id != -1:\n",
    "            database[db[\"db_id\"]][db[\"table_names_original\"][table_id]].append(col_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9cd9929-b1fe-4e0d-afcf-e154f34dbda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "spider = load_dataset(\"spider\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ba4f9e8-75fe-482c-ba36-90cdf7636ecf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['db_id', 'query', 'question', 'query_toks', 'query_toks_no_value', 'question_toks'],\n",
       "        num_rows: 7000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['db_id', 'query', 'question', 'query_toks', 'query_toks_no_value', 'question_toks'],\n",
       "        num_rows: 1034\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6ae543c-646c-463c-a5e1-7be7d3ca0d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def db_id_to_table(db_id):\n",
    "    global database\n",
    "    db = database[db_id]\n",
    "    table = [f\"{table}({','.join(db[table])})\" for table in db]\n",
    "    table = \", \".join(table)\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ddd6a4f3-ad3c-4a87-8f7f-adb609b6807f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.replace(\"\\xa0\", \" \").strip()\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text\n",
    "\n",
    "def clean_query(query):\n",
    "    query = clean_text(query).replace(\" , \", \", \")\n",
    "    if query[-1] == \";\":\n",
    "        query = query[:-1]\n",
    "    return query\n",
    "\n",
    "def get_prompt(tables, question):\n",
    "    question = clean_text(question)\n",
    "    prompt = f\"\"\"convert question and table into SQL query. tables: {tables}. question: {question}\"\"\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3169be0e-7871-418e-ae82-ce9c1a74e40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spider_preprocess_function(examples):\n",
    "    tables = db_id_to_table(examples[\"db_id\"])\n",
    "    examples[\"query\"] = clean_query(examples[\"query\"])\n",
    "    examples[\"prompt\"] = get_prompt(tables, examples[\"question\"])\n",
    "    return examples\n",
    "\n",
    "def spider_tokenize(examples):\n",
    "    return tokenizer(examples[\"prompt\"], text_target=examples[\"query\"], max_length=tokenizer.model_max_length, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1debf018-cc35-4f06-bded-b2339e654f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "spider_train = spider[\"train\"].map(spider_preprocess_function, remove_columns=['db_id', 'question', 'query_toks', 'query_toks_no_value', 'question_toks'])\n",
    "spider_val = spider[\"validation\"].map(spider_preprocess_function, remove_columns=['db_id', 'question', 'query_toks', 'query_toks_no_value', 'question_toks'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3905c93e-ace7-4839-a74e-766f15d22f16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'select count(*) from concert where stadium_id = (select stadium_id from stadium order by capacity desc limit 1)',\n",
       " 'prompt': 'convert question and table into SQL query. tables: stadium(Stadium_ID,Location,Name,Capacity,Highest,Lowest,Average), singer(Singer_ID,Name,Country,Song_Name,Song_release_year,Age,Is_male), concert(concert_ID,concert_Name,Theme,Stadium_ID,Year), singer_in_concert(concert_ID,Singer_ID). question: Find the number of concerts happened in the stadium with the highest capacity .'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spider_val[43]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a6c05c-dc02-4f32-af19-9287c9a93fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "spider_train = spider_train.map(spider_tokenize, remove_columns=['prompt', 'query'])\n",
    "spider_val = spider_val.map(spider_tokenize, remove_columns=['prompt', 'query'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803da0d9-a848-4242-b858-e46f8e1786c9",
   "metadata": {},
   "source": [
    "# CoSQL & SPARC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "806eb6ab-8e0c-419c-9261-92b9a52a265a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare table for cosql and sparc\n",
    "# with open(\"/mnt/c/Users/Jui/Projects/data/cosql_dataset/tables.json\") as json_file:\n",
    "#     json_data = json.load(json_file)\n",
    "    \n",
    "# database = dict()\n",
    "\n",
    "# for db in json_data:\n",
    "#     database[db[\"db_id\"]] = dict()\n",
    "#     for table in db[\"table_names_original\"]:\n",
    "#         database[db[\"db_id\"]][table] = []\n",
    "#     for column in db[\"column_names_original\"]:\n",
    "#         table_id = column[0]\n",
    "#         col_name = column[1]\n",
    "#         if table_id != -1:\n",
    "#             database[db[\"db_id\"]][db[\"table_names_original\"][table_id]].append(col_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8790b00f-ecf0-4fc7-9c68-24a69e7e5995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data\n",
    "def json_path_to_dataframe(path):\n",
    "    with open(path) as json_file:\n",
    "        json_data = json.load(json_file)\n",
    "        \n",
    "    df = pd.DataFrame(columns=[\"prompt\", \"query\"])\n",
    "\n",
    "    for row in json_data:\n",
    "        question = row[\"final\"][\"utterance\"]\n",
    "        query = row[\"final\"][\"query\"]\n",
    "\n",
    "        tables = db_id_to_table(row[\"database_id\"])\n",
    "        query = clean_query(query)\n",
    "        prompt = get_prompt(tables, question)\n",
    "\n",
    "        df = pd.concat([df, pd.DataFrame({\n",
    "            \"prompt\": [prompt],\n",
    "            \"query\": [query]\n",
    "        })], axis=0, ignore_index=True)\n",
    "    return df\n",
    "\n",
    "# cosql\n",
    "json_path_to_dataframe(\"/mnt/c/Users/Jui/Projects/data/cosql_dataset/sql_state_tracking/cosql_dev.json\").to_csv(\"cosql_dev.csv\", index=False)\n",
    "json_path_to_dataframe(\"/mnt/c/Users/Jui/Projects/data/cosql_dataset/sql_state_tracking/cosql_train.json\").to_csv(\"cosql_train.csv\", index=False)\n",
    "\n",
    "# sparc\n",
    "json_path_to_dataframe(\"/mnt/c/Users/Jui/Projects/data/sparc/dev.json\").to_csv(\"sparc_dev.csv\", index=False)\n",
    "json_path_to_dataframe(\"/mnt/c/Users/Jui/Projects/data/sparc/train.json\").to_csv(\"sparc_train.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c2b1d8-96c1-4056-8a89-8b54224aa4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosql = load_dataset(\"csv\", data_files={\"dev\": \"cosql_dev.csv\", \"train\": \"cosql_train.csv\"})\n",
    "sparc = load_dataset(\"csv\", data_files={\"dev\": \"sparc_dev.csv\", \"train\": \"sparc_train.csv\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "085c5d61-8451-4613-bef3-96c12250042f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    dev: Dataset({\n",
       "        features: ['prompt', 'query'],\n",
       "        num_rows: 293\n",
       "    })\n",
       "    train: Dataset({\n",
       "        features: ['prompt', 'query'],\n",
       "        num_rows: 2159\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "04f5b8d1-52e7-4bdf-8d84-34413cdf4da2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prompt': 'convert question and table into SQL query. tables: players(player_id,first_name,last_name,hand,birth_date,country_code), matches(best_of,draw_size,loser_age,loser_entry,loser_hand,loser_ht,loser_id,loser_ioc,loser_name,loser_rank,loser_rank_points,loser_seed,match_num,minutes,round,score,surface,tourney_date,tourney_id,tourney_level,tourney_name,winner_age,winner_entry,winner_hand,winner_ht,winner_id,winner_ioc,winner_name,winner_rank,winner_rank_points,winner_seed,year), rankings(ranking_date,ranking,player_id,ranking_points,tours). question: Find the average age of losers and winners of all matches.',\n",
       " 'query': 'SELECT avg(loser_age), avg(winner_age) FROM matches'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosql[\"dev\"][32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0e3e8452-e557-4888-bb96-2d7df5f3edcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    dev: Dataset({\n",
       "        features: ['prompt', 'query'],\n",
       "        num_rows: 422\n",
       "    })\n",
       "    train: Dataset({\n",
       "        features: ['prompt', 'query'],\n",
       "        num_rows: 3034\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f239def6-8bc9-4bfe-ab6b-5d33c332271a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prompt': 'convert question and table into SQL query. tables: airlines(uid,Airline,Abbreviation,Country), airports(City,AirportCode,AirportName,Country,CountryAbbrev), flights(Airline,FlightNo,SourceAirport,DestAirport). question: What country is Jetblue Airways affiliated with?',\n",
       " 'query': 'SELECT Country FROM AIRLINES WHERE Airline = \"JetBlue Airways\"'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparc[\"dev\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c909b4be-3253-40e1-a091-a2c83837992c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def general_tokenize(examples):\n",
    "    return tokenizer(examples[\"prompt\"], text_target=examples[\"query\"], max_length=tokenizer.model_max_length, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fe066278-a2c5-4da6-9d85-4a0b094ccb59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.005349874496459961,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 30,
       "postfix": null,
       "prefix": "Map",
       "rate": null,
       "total": 2159,
       "unit": " examples",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2159 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.00366973876953125,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 30,
       "postfix": null,
       "prefix": "Map",
       "rate": null,
       "total": 293,
       "unit": " examples",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/293 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.004305124282836914,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 30,
       "postfix": null,
       "prefix": "Map",
       "rate": null,
       "total": 3034,
       "unit": " examples",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3034 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.004216670989990234,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 30,
       "postfix": null,
       "prefix": "Map",
       "rate": null,
       "total": 422,
       "unit": " examples",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/422 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cosql_train = cosql[\"train\"].map(general_tokenize, remove_columns=['prompt', 'query'])\n",
    "cosql_val = cosql[\"dev\"].map(general_tokenize, remove_columns=['prompt', 'query'])\n",
    "\n",
    "sparc_train = sparc[\"train\"].map(general_tokenize, remove_columns=['prompt', 'query'])\n",
    "sparc_val = sparc[\"dev\"].map(general_tokenize, remove_columns=['prompt', 'query'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036df6d9-325c-4a4f-aafd-a56428f7b36a",
   "metadata": {},
   "source": [
    "## Mixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bfc4f20f-5b3b-4faa-b156-088ca0ca8bac",
   "metadata": {
    "id": "QEAiP56ylOSZ"
   },
   "outputs": [],
   "source": [
    "from datasets import concatenate_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "da945d6d-a09c-4c1f-bd84-5015ab43f03c",
   "metadata": {
    "id": "WdlmhFH-k8pE"
   },
   "outputs": [],
   "source": [
    "train_dataset = concatenate_datasets([spider_train, cosql_train, sparc_train])\n",
    "val_dataset = concatenate_datasets([spider_val, cosql_val, sparc_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9ec22dbe-9352-4fab-a060-59651dc98943",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 12193\n",
       "})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b430feec-67c5-4230-bfd3-e9c18026953b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 1749\n",
       "})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2207ff09-1c58-4f88-90f3-a43eaabd48fc",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6dbd790d-821c-4ca8-b97f-08f18c808061",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32101"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6ce01a82-0cb5-48a9-8cf1-c3996ab021f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# declare model\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-base\")\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3c01de80-958b-4985-aba8-7af161cdbc42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "990145536"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_memory_footprint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "da5fa751-43b1-4c39-9b4d-c0310e6bfaf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# declare data collator\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6cadb9ae-9474-4fb6-8750-ec641a1adff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# declare training arguments\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./model\",\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=381,\n",
    "    logging_steps=381,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=381,\n",
    "    learning_rate=1e-4,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    gradient_accumulation_steps=8,\n",
    "    # gradient_checkpointing=True,\n",
    "    # warmup_ratio=0.01,\n",
    "    # weight_decay=0.01,\n",
    "    save_total_limit=2,\n",
    "    num_train_epochs=10,\n",
    "    # fp16=True,\n",
    "    # bf16=True, \n",
    "    # predict_with_generate=True,\n",
    "    # generation_max_length=512,\n",
    "    # generation_num_beams=None,\n",
    "    # lr_scheduler_type=\"cosine\",\n",
    "    # dataloader_num_workers=2,\n",
    "    greater_is_better=False,\n",
    "    # metric_for_best_model=\"eval_loss\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7917f9d5-9831-4166-876d-974376bd6bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "\n",
    "# def compute_metrics(eval_pred):\n",
    "#     predictions, labels = eval_pred\n",
    "#     # Decode generated summaries into text\n",
    "#     decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "#     # Replace -100 in the labels as we can't decode them\n",
    "#     labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "#     # Decode reference summaries into text\n",
    "#     decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "#     # ROUGE expects a newline after each sentence\n",
    "#     decoded_preds = [\"\\n\".join(sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
    "#     decoded_labels = [\"\\n\".join(sent_tokenize(label.strip())) for label in decoded_labels]\n",
    "#     # Compute ROUGE scores\n",
    "#     result = rouge_score.compute(\n",
    "#         predictions=decoded_preds, references=decoded_labels, use_stemmer=True\n",
    "#     )\n",
    "#     # Extract the median scores\n",
    "#     result = {key: value.mid.fmeasure * 100 for key, value in result.items()}\n",
    "#     return {k: round(v, 4) for k, v in result.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "990ef930-b1f3-4707-90ac-b1696d95da26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# declare trainer\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    # compute_metrics=compute_metrics,\n",
    ") # you can evaluate by using compute_metrics function above, but I comment out for the faster training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b774a025-c79d-445c-9c45-30ce0fbab0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()\n",
    "# trainer.train(resume_from_checkpoint=\"./results/checkpoint-13000\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b192edca-1108-40d3-962c-4409ad32ab20",
   "metadata": {},
   "source": [
    "## Upload Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8c111f5d-d236-4530-85ef-54372f017ece",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40e5d33320ca43d683340d2cf190db1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "61fd1b96-2667-49c6-aa48-a42f939878c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.004305124282836914,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 30,
       "postfix": null,
       "prefix": "pytorch_model.bin",
       "rate": null,
       "total": 990239029,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e71962b2996f40d8ae3011cbef3b9583",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/990M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.00562286376953125,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 30,
       "postfix": null,
       "prefix": "Upload 1 LFS files",
       "rate": null,
       "total": 1,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aecb95118eb14e549d0dfd223fd834be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 1 LFS files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/juierror/flan-t5-text2sql-with-schema-v2/commit/01a1b7a8ee9722b648c2add3f2477a1824b666a2', commit_message='Upload T5ForConditionalGeneration', commit_description='', oid='01a1b7a8ee9722b648c2add3f2477a1824b666a2', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.push_to_hub(repo_id=\"juierror/flan-t5-text2sql-with-schema-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b888562d-6083-45ec-bc05-f50096294b3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0059337615966796875,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 30,
       "postfix": null,
       "prefix": "Upload 1 LFS files",
       "rate": null,
       "total": 1,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8f732096fcf45d8ad42cfbf25551810",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 1 LFS files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.005797624588012695,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 30,
       "postfix": null,
       "prefix": "spiece.model",
       "rate": null,
       "total": 791656,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb97d0f1763d48f2bf2f56be8ff2b677",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/juierror/flan-t5-text2sql-with-schema-v2/commit/0d80cff0d64cd6833cce6ac61ede8af43340b339', commit_message='Upload tokenizer', commit_description='', oid='0d80cff0d64cd6833cce6ac61ede8af43340b339', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.push_to_hub(repo_id=\"juierror/flan-t5-text2sql-with-schema-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd0522d-bfaa-4f9a-b7bc-e7a76033b2ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
